import os
import ffmpeg
import cv2
import mediapipe as mp
import numpy as np

# í•˜ì´ë¼ì´íŠ¸ ì €ì¥ í´ë”
output_dir = 'wobble_highlights'
os.makedirs(output_dir, exist_ok=True)

# ë¶„ì„ ëŒ€ìƒ ë™ì˜ìƒ ë¦¬ìŠ¤íŠ¸ (í´ë”ë‚˜ ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •)
video_files = [
    '1round.mp4',
    '2round.mp4',
    '3round.mp4',
    'spar3.mp4'
]

# ë¯¸ë””ì–´íŒŒì´í”„ ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False)

highlight_files = []


def extract_wobbles(video_path, video_index):
    global highlight_files
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_idx = 0
    wobble_frames = []
    prev_angle = None
    prev_center = None
    prev_right_wrist = None
    prev_left_wrist = None
    skip_until_frame = -1

    while cap.isOpened():

        if frame_idx < skip_until_frame:
            # ê±´ë„ˆë›°ê¸°
            frame_idx += 1
            cap.grab()
            continue

        ret, frame = cap.read()
        if not ret:
            break

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = pose.process(rgb)

        if result.pose_landmarks:
            lm = result.pose_landmarks.landmark
            left_shoulder = lm[mp_pose.PoseLandmark.LEFT_SHOULDER]
            right_shoulder = lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]
            left_hip = lm[mp_pose.PoseLandmark.LEFT_HIP]
            right_hip = lm[mp_pose.PoseLandmark.RIGHT_HIP]

            cx = np.mean([left_shoulder.x, right_shoulder.x, left_hip.x, right_hip.x])
            cy = np.mean([left_shoulder.y, right_shoulder.y, left_hip.y, right_hip.y])
            center = np.array([cx, cy])

            dx = right_shoulder.x - left_shoulder.x
            dy = right_shoulder.y - left_shoulder.y
            angle = np.degrees(np.arctan2(dy, dx))

            # ì†ëª© (ì˜¤ë¥¸ì†) ìœ„ì¹˜
            right_wrist = lm[mp_pose.PoseLandmark.RIGHT_WRIST]
            wrist_speed = 0

            left_wrist = lm[mp_pose.PoseLandmark.LEFT_WRIST]

            if prev_angle is not None and prev_center is not None:
                angle_diff = abs(angle - prev_angle)
                move_dist = np.linalg.norm(center - prev_center)

                # ì†ëª© ì†ë„ ê³„ì‚°
                if prev_right_wrist:
                    wrist_speed = max(wrist_speed, np.linalg.norm([
                        right_wrist.x - prev_right_wrist.x,
                        right_wrist.y - prev_right_wrist.y
                    ]))

                # ì†ëª© ì†ë„ ê³„ì‚°
                if prev_left_wrist:
                    wrist_speed = max(wrist_speed, np.linalg.norm([
                        left_wrist.x - prev_left_wrist.x,
                        left_wrist.y - prev_left_wrist.y
                    ]))

                # ìƒˆë¡œìš´ íœ˜ì²­ + íƒ€ê²© ì¡°ê±´
                if angle_diff > 20 and move_dist > 0.05 and wrist_speed > 0.1:
                    time = frame_idx / fps
                    print(f"ğŸ¯ íƒ€ê²©+íœ˜ì²­ ê°ì§€ at {time:.2f}s")
                    wobble_frames.append(time)

                    # 3ì´ˆ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ í›„ 2ì´ˆê°„ ìŠ¤í‚µ
                    skip_duration = 2  # seconds
                    skip_until_frame = frame_idx + int(skip_duration * fps)

            prev_angle = angle
            prev_center = center
            prev_right_wrist = right_wrist
            prev_left_wrist = left_wrist

        frame_idx += 1

    cap.release()

    wobble_times = sorted(set(int(t) for t in wobble_frames))

    # í•˜ì´ë¼ì´íŠ¸ í´ë¦½ ì €ì¥
    for i, sec in enumerate(wobble_times):
        start = max(sec - 1, 0)
        out_filename = f"video{video_index}_wobble_{i + 1}.mp4"
        output_path = os.path.abspath(os.path.join(output_dir, out_filename))
        highlight_files.append(output_path)

        (
            ffmpeg
            .input(os.path.abspath(video_path), ss=start, t=3)
            .output(output_path)
            .run(overwrite_output=True)
        )


# ëª¨ë“  ì˜ìƒì— ëŒ€í•´ ì²˜ë¦¬ ì‹¤í–‰
for idx, video in enumerate(video_files):
    print(f"â–¶ Processing {video} ...")
    extract_wobbles(video, idx + 1)

# í•©ì¹  íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
concat_file_path = os.path.join(output_dir, "file_list.txt")
with open(concat_file_path, 'w') as f:
    for path in highlight_files:
        f.write(f"file '{path}'\n")

# ìµœì¢… í•˜ì´ë¼ì´íŠ¸ ì˜ìƒìœ¼ë¡œ í•©ì¹˜ê¸°
final_output_path = os.path.join(output_dir, "final_highlight.mp4")
ffmpeg.input(concat_file_path, format='concat', safe=0).output(final_output_path, c='copy').run()

print(f"\nâœ… ëª¨ë“  í•˜ì´ë¼ì´íŠ¸ë¥¼ í•©ì¹œ ì˜ìƒì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {final_output_path}")
